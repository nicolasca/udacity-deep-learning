### (Optional) 
### TODO: Test performance of anotherface detection algorithm.
### Feel free to use as many code cells as needed.
from torchvision import datasets, models, transforms
import torch
from torch.utils.data.sampler import SubsetRandomSampler
import numpy as np
from PIL import ImageFile
ImageFile.LOAD_TRUNCATED_IMAGES = True

# load and transform data using ImageFolder
# VGG-16 Takes 224x224 images as input, so we resize all of them
data_transform = transforms.Compose([transforms.RandomResizedCrop(224), 
                                      transforms.ToTensor()])

data = datasets.ImageFolder('/data', transform=data_transform)

# print out some data stats
print('Num human images: ', len(data))


# check if CUDA is available
train_on_gpu = torch.cuda.is_available()

if not train_on_gpu:
    print('CUDA is not available.  Training on CPU ...')
else:
    print('CUDA is available!  Training on GPU ...')

# define dataloader parameters
batch_size = 100
num_workers=0

# Split the data into train, validation and test sets
dataset_size = len(data)
dataset_indices = list(range(dataset_size))
test_split = int(np.floor(0.9 * dataset_size)) # Test size = 10%

# Shuffle the data in case it's organized by class
np.random.shuffle(dataset_indices)

train_indices, test_indices = dataset_indices[:test_split], dataset_indices[test_split:]

# Split the train into train + validation
train_size = len(train_indices)
validation_split = int(np.floor(0.8 * train_size)) # Validation size = 20%
train_indices, validation_indices = train_indices[: validation_split], train_indices[validation_split:]

# Samplers
train_sampler = SubsetRandomSampler(train_indices)
validation_sampler = SubsetRandomSampler(validation_indices)
test_sampler = SubsetRandomSampler(test_indices)
                       
print("Training set size: %d" % len(train_indices))
print("Validation set size: %d" % len(validation_indices))
print("Test set size: %d" % len(test_indices))
                      

# prepare data loaders
train_loader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=False,
                                           num_workers=num_workers, sampler=train_sampler)
valid_loader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=False,
                                           num_workers=num_workers, sampler=validation_sampler)
test_loader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=False,
                                           num_workers=num_workers, sampler=test_sampler)

# Load the pretrained model from pytorch
vgg16 = models.vgg16(pretrained=True)

# print out the model structure
print(vgg16)


# Freeze training for all "features" layers
for param in vgg16.features.parameters():
    param.requires_grad = False

## new layers automatically have requires_grad = True
import torch.nn as nn

# Replace the laster layer of the FC layers
n_features = vgg16.classifier[6].in_features
last_layer = nn.Linear(n_features, 2)
vgg16.classifier[6] = last_layer

# after completing your model, if GPU is available, move the model to GPU
if train_on_gpu:
    vgg16.cuda()
    
# Check if output number is correct
print(vgg16.classifier[6].out_features)

import torch.optim as optim

# specify loss function (categorical cross-entropy)
criterion = nn.CrossEntropyLoss()

# specify optimizer (stochastic gradient descent) and learning rate = 0.001
optimizer = optim.SGD(vgg16.classifier.parameters(), lr=0.001)

# number of epochs to train the model
n_epochs = 2

## TODO complete epoch and training batch loops
## These loops should update the classifier-weights of this model
## And track (and print out) the training loss over time

for epoch in range(1, n_epochs+1):
    train_loss = 0
    valid_loss = 0

    # Train the model
    vgg16.train()
    for data, target in train_loader:
        target = target - 1
        if train_on_gpu:
            data, target = data.cuda(), target.cuda()
        
        optimizer.zero_grad()

        output = vgg16(data)
        loss = criterion(output, target)
        loss.backward()
        optimizer.step()

        train_loss += loss.item()*data.size(0)
        
    ######################    
    # validate the model #
    ######################
    vgg16.eval()
    for data, target in valid_loader:
        # move tensors to GPU if CUDA is available
        if train_on_gpu:
            data, target = data.cuda(), target.cuda()
        # forward pass: compute predicted outputs by passing inputs to the model
        output = vgg16(data)
        # calculate the batch loss
        loss = criterion(output, target)
        # update average validation loss 
        valid_loss += loss.item()*data.size(0)
    
    # calculate average losses
    train_loss = train_loss/len(training_loader.dataset)
    valid_loss = valid_loss/len(validation_loader.dataset)
        
    # print training/validation statistics 
    print('Epoch: {} \tTraining Loss: {:.6f} \tValidation Loss: {:.6f}'.format(
        epoch, train_loss, valid_loss))
    
    # save model if validation loss has decreased
    if valid_loss <= valid_loss_min:
        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(
        valid_loss_min,
        valid_loss))
        torch.save(model.state_dict(), 'model_cifar.pt')
        valid_loss_min = valid_loss
 